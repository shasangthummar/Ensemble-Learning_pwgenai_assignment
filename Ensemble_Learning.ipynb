{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**THEORY QUESTION AND ANSWERS**"
      ],
      "metadata": {
        "id": "X2jkaGknJXhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## question 1: Can we use Bagging for regression problems?\n",
        "\n",
        "**Yes**, Bagging (Bootstrap Aggregating) can definitely be used for regression problems.\n",
        "\n",
        "* In **Bagging Regressor**, multiple regression models (often decision trees called **regression trees**) are trained independently on different **bootstrap samples** of the training data. Each bootstrap sample is generated by randomly selecting data points **with replacement**, so each model sees a slightly different dataset.\n",
        "* When predicting, the individual regressors produce continuous output values, and the final prediction is computed by **averaging** all these individual predictions.\n",
        "* This averaging helps to **reduce variance** and **improve stability**, making the ensemble prediction less sensitive to noise or overfitting compared to a single regression model.\n",
        "\n",
        "**Example:** Predicting house prices using Bagging Regressor often leads to more accurate and stable predictions than using a single decision tree regressor.\n",
        "\n",
        "---\n",
        "\n",
        "## question 2: What is the difference between multiple model training and single model training?\n",
        "\n",
        "| Aspect               | Single Model Training              | Multiple Model Training                               |\n",
        "| -------------------- | ---------------------------------- | ----------------------------------------------------- |\n",
        "| **Number of Models** | One                                | Multiple (ensemble of models)                         |\n",
        "| **Training Data**    | Entire training set                | Different subsets (often bootstrap samples) per model |\n",
        "| **Goal**             | Find one best model                | Combine multiple models to improve accuracy           |\n",
        "| **Variance**         | Can be high (prone to overfitting) | Reduced by averaging/voting over models               |\n",
        "| **Bias**             | Depends on model complexity        | May reduce bias in methods like boosting              |\n",
        "| **Robustness**       | Less robust to noise/outliers      | More robust due to model diversity                    |\n",
        "| **Training Time**    | Usually faster                     | More computationally intensive                        |\n",
        "\n",
        "### Why multiple models?\n",
        "\n",
        "Training multiple models on different versions of the data and combining their predictions allows the ensemble to **average out errors** from individual models, leading to better generalization on unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "## question 3: Explain the concept of feature randomness in Random Forest.\n",
        "\n",
        "Random Forest introduces **two types of randomness** to create a diverse ensemble of decision trees:\n",
        "\n",
        "1. **Bootstrap Sampling of Data:** Each tree is trained on a different random subset (with replacement) of the training data.\n",
        "\n",
        "2. **Random Feature Selection (Feature Randomness):**\n",
        "   At each node split during tree construction, instead of considering **all features** to find the best split, Random Forest selects a **random subset of features**. The best split is found only among this subset.\n",
        "\n",
        "### Why feature randomness?\n",
        "\n",
        "* It **decorrelates the trees** in the forest. Because trees see different features and data samples, their errors are less likely to be correlated.\n",
        "* This reduces the overall variance of the ensemble.\n",
        "* It **prevents trees from all relying on the strongest predictors**, encouraging more diverse trees and improving generalization.\n",
        "\n",
        "---\n",
        "\n",
        "## question 4: What is OOB (Out-Of-Bag) Score?\n",
        "\n",
        "**Out-Of-Bag (OOB) score** is an **internal validation technique** in Bagging-based algorithms like Random Forest:\n",
        "\n",
        "* When creating bootstrap samples, about **one-third of the training data is left out** for each tree (since sampling is with replacement).\n",
        "* These **left-out samples** are called **OOB samples** for that tree.\n",
        "* The model's predictions on these OOB samples serve as a **built-in validation** to estimate model performance **without using a separate test set**.\n",
        "* Aggregating predictions over all trees’ OOB samples provides a reliable estimate of the model’s generalization accuracy.\n",
        "\n",
        "**Advantage:** Saves data for training while still providing a performance measure.\n",
        "\n",
        "---\n",
        "\n",
        "## question 5: How can you measure the importance of features in a Random Forest model?\n",
        "\n",
        "Two common methods to measure feature importance:\n",
        "\n",
        "1. **Mean Decrease in Impurity (MDI):**\n",
        "\n",
        "   * Every time a feature is used to split a node, the impurity (e.g., Gini or entropy) decreases.\n",
        "   * Summing these decreases over all trees and normalizing gives a measure of how important the feature is in reducing uncertainty.\n",
        "\n",
        "2. **Permutation Importance:**\n",
        "\n",
        "   * Randomly shuffle a single feature’s values across the dataset.\n",
        "   * Measure the increase in prediction error caused by this shuffling.\n",
        "   * A large increase means the feature was important; little change means the feature was not influential.\n",
        "\n",
        "**Interpretation:**\n",
        "These scores help identify which features contribute most to prediction, useful for feature selection and model interpretation.\n",
        "\n",
        "---\n",
        "\n",
        "## question 6: Explain the working principle of a Bagging Classifier.\n",
        "\n",
        "* **Bootstrap sampling:** Generate multiple different training datasets by randomly sampling with replacement.\n",
        "* **Train multiple classifiers:** Train an independent base classifier (e.g., decision tree) on each bootstrap sample.\n",
        "* **Aggregate predictions:** For classification, use **majority voting** among all classifiers to decide the final output class.\n",
        "\n",
        "### Benefits:\n",
        "\n",
        "* Reduces **variance** and **overfitting** compared to a single classifier.\n",
        "* More stable and accurate predictions.\n",
        "* Simple yet powerful ensemble technique.\n",
        "\n",
        "---\n",
        "\n",
        "## question 7: How do you evaluate a Bagging Classifier's performance?\n",
        "\n",
        "Evaluate using common classification metrics such as:\n",
        "\n",
        "* **Accuracy:** Percentage of correctly classified instances.\n",
        "* **Precision, Recall, F1-Score:** Useful for imbalanced datasets.\n",
        "* **Confusion Matrix:** Understand types of errors (false positives, false negatives).\n",
        "* **Cross-validation:** To estimate performance robustness.\n",
        "* **Out-Of-Bag (OOB) Score:** Provides an internal estimate of accuracy without needing a validation set.\n",
        "\n",
        "---\n",
        "\n",
        "## question 8: How does a Bagging Regressor work?\n",
        "\n",
        "* Like Bagging Classifier but for regression.\n",
        "* Multiple regressors are trained on different bootstrap samples.\n",
        "* Each regressor predicts a continuous value.\n",
        "* The final prediction is the **average** of all individual predictions.\n",
        "* Averaging reduces model variance and improves stability.\n",
        "\n",
        "---\n",
        "\n",
        "## question 9: What is the main advantage of ensemble techniques?\n",
        "\n",
        "* **Improved accuracy:** By combining multiple models, ensembles reduce errors due to variance and/or bias.\n",
        "* **Better generalization:** Ensemble models usually perform better on unseen data than individual models.\n",
        "* **Robustness:** Less sensitive to noise or outliers.\n",
        "* **Flexibility:** Can combine different types of base learners.\n",
        "\n",
        "---\n",
        "\n",
        "## question 10: What is the main challenge of ensemble methods?\n",
        "\n",
        "* **Computational Complexity:** Training and maintaining multiple models can be resource-intensive.\n",
        "* **Interpretability:** Ensembles are often harder to interpret compared to single models.\n",
        "* **Parameter Tuning:** May require tuning more hyperparameters.\n",
        "* **Diminishing Returns:** Adding too many models might not always improve performance significantly.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-z14oVApIbCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## question 11: Explain the key idea behind ensemble techniques.\n",
        "\n",
        "Ensemble techniques combine predictions from **multiple individual models** (called base learners) to produce a single, stronger prediction.\n",
        "\n",
        "* The intuition: While a single model might make mistakes, multiple diverse models are less likely to all make the same errors.\n",
        "* Combining their predictions (by voting or averaging) reduces **variance**, **bias**, or both.\n",
        "* This leads to improved **accuracy**, **robustness**, and **generalization**.\n",
        "\n",
        "Popular ensemble methods include **Bagging** (reduces variance), **Boosting** (reduces bias), and **Stacking** (combines different model types).\n",
        "\n",
        "---\n",
        "\n",
        "## question 12: What is a Random Forest Classifier?\n",
        "\n",
        "A **Random Forest Classifier** is an ensemble of decision trees used for classification.\n",
        "\n",
        "* Each tree is trained on a **bootstrap sample** of the data.\n",
        "* At each split, a random subset of features is considered (**feature randomness**).\n",
        "* The final prediction is made by **majority voting** among all trees.\n",
        "\n",
        "Random Forests are robust, handle high-dimensional data well, reduce overfitting compared to a single tree, and provide feature importance measures.\n",
        "\n",
        "---\n",
        "\n",
        "## question 13: What are the main types of ensemble techniques?\n",
        "\n",
        "The main types are:\n",
        "\n",
        "1. **Bagging (Bootstrap Aggregating):**\n",
        "   Builds multiple independent models on bootstrapped data samples and aggregates results (e.g., Random Forest).\n",
        "\n",
        "2. **Boosting:**\n",
        "   Builds models sequentially where each new model corrects errors of the previous ones (e.g., AdaBoost, Gradient Boosting).\n",
        "\n",
        "3. **Stacking:**\n",
        "   Combines multiple different models by training a meta-model on their predictions.\n",
        "\n",
        "Each method improves predictive performance differently by reducing variance, bias, or combining strengths.\n",
        "\n",
        "---\n",
        "\n",
        "## question 14: What is ensemble learning in machine learning?\n",
        "\n",
        "**Ensemble learning** is a technique where multiple models are combined to solve a particular problem and improve performance.\n",
        "\n",
        "* Instead of relying on a single model, ensemble learning builds and integrates many models.\n",
        "* The idea is that collective wisdom of models yields better predictions than individuals.\n",
        "* It is widely used for both classification and regression tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## question 15: When should we avoid using ensemble methods?\n",
        "\n",
        "Avoid ensembles when:\n",
        "\n",
        "* **Interpretability is critical:** Ensembles can be black boxes.\n",
        "* **Limited computational resources:** Training many models can be costly.\n",
        "* **Small datasets:** Ensembles may overfit if training data is insufficient.\n",
        "* When a **simple model** already performs very well.\n",
        "* For **real-time applications** needing extremely fast inference.\n",
        "\n",
        "---\n",
        "\n",
        "## question 16: How does Bagging help in reducing overfitting?\n",
        "\n",
        "* Bagging reduces overfitting by training models on different **random subsets of data** (bootstrap samples).\n",
        "* Individual models overfit to their specific samples, but when combined by voting or averaging, their errors cancel out.\n",
        "* This lowers the overall model variance without increasing bias much.\n",
        "* Hence, the ensemble generalizes better than any single overfitted model.\n",
        "\n",
        "---\n",
        "\n",
        "## question 17: Why is Random Forest better than a single Decision Tree?\n",
        "\n",
        "* **Less overfitting:** Random Forest averages multiple trees, reducing variance.\n",
        "* **More robust:** Due to randomness in data and features, trees are decorrelated.\n",
        "* **Handles high-dimensional data well:** Can select informative features automatically.\n",
        "* **Provides feature importance:** Useful for interpretability.\n",
        "* **Good out-of-the-box performance:** Requires less tuning than single trees.\n",
        "\n",
        "---\n",
        "\n",
        "## question 18: What is the role of bootstrap sampling in Bagging?\n",
        "\n",
        "* Bootstrap sampling creates multiple different training datasets by sampling **with replacement**.\n",
        "* Each model in the Bagging ensemble trains on a different bootstrap sample.\n",
        "* This introduces **diversity** among models, making their errors less correlated.\n",
        "* Aggregating diverse models improves overall prediction accuracy and stability.\n",
        "\n",
        "---\n",
        "\n",
        "## question 19: What are some real-world applications of ensemble techniques?\n",
        "\n",
        "* **Finance:** Credit scoring, fraud detection.\n",
        "* **Healthcare:** Disease diagnosis, medical imaging.\n",
        "* **Marketing:** Customer segmentation, churn prediction.\n",
        "* **Natural Language Processing:** Spam filtering, sentiment analysis.\n",
        "* **Computer Vision:** Image classification, object detection.\n",
        "* **Recommendation Systems:** Collaborative filtering ensembles.\n",
        "\n",
        "---\n",
        "\n",
        "## question 20: What is the difference between Bagging and Boosting?\n",
        "\n",
        "| Aspect                | Bagging                            | Boosting                                    |\n",
        "| --------------------- | ---------------------------------- | ------------------------------------------- |\n",
        "| **Goal**              | Reduce variance                    | Reduce bias                                 |\n",
        "| **Training**          | Models trained independently       | Models trained sequentially                 |\n",
        "| **Data sampling**     | Bootstrap samples with replacement | Weighted samples focusing on errors         |\n",
        "| **Model weight**      | Equal voting/averaging             | Models weighted by performance              |\n",
        "| **Error correction**  | No direct correction among models  | Each model tries to correct previous errors |\n",
        "| **Common algorithms** | Random Forest                      | AdaBoost, Gradient Boosting, XGBoost        |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RCkch0AsIhUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**coding question and answers**"
      ],
      "metadata": {
        "id": "bYua3jssIlQi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cof2DPwIS99",
        "outputId": "cfe5a795-e904-46aa-c94a-06ec6f216a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "# question 21: Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Bagging Classifier with Decision Trees (use 'estimator' instead of deprecated 'base_estimator')\n",
        "bag_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "print(\"Bagging Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 22: Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Bagging Regressor with Decision Trees (updated parameter name)\n",
        "bag_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bag_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = bag_reg.predict(X_test)\n",
        "\n",
        "# Calculate and print Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Bagging Regressor Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3_TqiuOJmUN",
        "outputId": "b53ef244-aae6-4b73-cd06-c5c5ade47bc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor Mean Squared Error: 0.25787382250585034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 23: Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Feature importance\n",
        "importances = rf_clf.feature_importances_\n",
        "\n",
        "# Print feature importance scores\n",
        "for name, importance in zip(cancer.feature_names, importances):\n",
        "    print(f\"{name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEumWTqlJnwA",
        "outputId": "9da56ffa-c05c-4767-8af1-0c0d042cb544"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean radius: 0.0323\n",
            "mean texture: 0.0111\n",
            "mean perimeter: 0.0601\n",
            "mean area: 0.0538\n",
            "mean smoothness: 0.0062\n",
            "mean compactness: 0.0092\n",
            "mean concavity: 0.0806\n",
            "mean concave points: 0.1419\n",
            "mean symmetry: 0.0033\n",
            "mean fractal dimension: 0.0031\n",
            "radius error: 0.0164\n",
            "texture error: 0.0032\n",
            "perimeter error: 0.0118\n",
            "area error: 0.0295\n",
            "smoothness error: 0.0059\n",
            "compactness error: 0.0046\n",
            "concavity error: 0.0058\n",
            "concave points error: 0.0034\n",
            "symmetry error: 0.0040\n",
            "fractal dimension error: 0.0071\n",
            "worst radius: 0.0780\n",
            "worst texture: 0.0188\n",
            "worst perimeter: 0.0743\n",
            "worst area: 0.1182\n",
            "worst smoothness: 0.0118\n",
            "worst compactness: 0.0175\n",
            "worst concavity: 0.0411\n",
            "worst concave points: 0.1271\n",
            "worst symmetry: 0.0129\n",
            "worst fractal dimension: 0.0069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 24: Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Using Boston dataset from before\n",
        "# Initialize models\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train\n",
        "dt_reg.fit(X_train, y_train)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "dt_pred = dt_reg.predict(X_test)\n",
        "rf_pred = rf_reg.predict(X_test)\n",
        "\n",
        "# MSE\n",
        "print(\"Decision Tree MSE:\", mean_squared_error(y_test, dt_pred))\n",
        "print(\"Random Forest MSE:\", mean_squared_error(y_test, rf_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLqXYi0pJqoq",
        "outputId": "d760ac12-9abf-46bf-901f-eb8d998f2101"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE: 0.05847953216374269\n",
            "Random Forest MSE: 0.034179532163742685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 25: Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_clf_oob = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "rf_clf_oob.fit(X_train, y_train)\n",
        "\n",
        "print(\"OOB Score:\", rf_clf_oob.oob_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lxq3H6IKMbF",
        "outputId": "00228c25-6282-4a66-ee68-1cb212184fb8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9547738693467337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 26: Train a Bagging Classifier using SVM as a base estimator and print accuracy.\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Bagging Classifier with SVM (updated parameter name)\n",
        "bag_svm = BaggingClassifier(estimator=SVC(probability=True), n_estimators=20, random_state=42)\n",
        "\n",
        "# Train\n",
        "bag_svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = bag_svm.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Bagging Classifier with SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIYgCzMnKONN",
        "outputId": "002f607d-84b0-46d8-9f44-f9bfc26f3caf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier with SVM Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 27: Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "for n_trees in [10, 50, 100, 200]:\n",
        "    rf = RandomForestClassifier(n_estimators=n_trees, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Random Forest with {n_trees} trees Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX-uVYxNKclJ",
        "outputId": "154ee348-d690-4b52-fc21-b06d3e2f1834"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest with 10 trees Accuracy: 1.0000\n",
            "Random Forest with 50 trees Accuracy: 1.0000\n",
            "Random Forest with 100 trees Accuracy: 1.0000\n",
            "Random Forest with 200 trees Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # question 28: Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset (using Breast Cancer as it's a binary classification problem suitable for AUC)\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Bagging Classifier with Logistic Regression\n",
        "# LogisticRegression requires probability=True for AUC calculation\n",
        "bag_logreg = BaggingClassifier(estimator=LogisticRegression(solver='liblinear'), n_estimators=50, random_state=42)\n",
        "\n",
        "# Train\n",
        "bag_logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities on test data (needed for AUC)\n",
        "y_prob_pred = bag_logreg.predict_proba(X_test)[:, 1] # Probability of the positive class\n",
        "\n",
        "# Calculate and print AUC score\n",
        "auc_score = roc_auc_score(y_test, y_prob_pred)\n",
        "print(\"Bagging Classifier with Logistic Regression AUC:\", auc_score)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNSYFYFmKtWj",
        "outputId": "eecbcb47-55b8-409c-d1ee-f06b521487d6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier with Logistic Regression AUC: 0.9983833039388595\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 29: Train a Random Forest Regressor and analyze feature importance scores.\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "importances = rf_reg.feature_importances_\n",
        "for feature, importance in zip(housing.feature_names, importances):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUrGvxHMLLUe",
        "outputId": "0861c2f2-b746-43af-bae5-e7ae381bfae5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedInc: 0.5260\n",
            "HouseAge: 0.0547\n",
            "AveRooms: 0.0472\n",
            "AveBedrms: 0.0300\n",
            "Population: 0.0317\n",
            "AveOccup: 0.1382\n",
            "Latitude: 0.0861\n",
            "Longitude: 0.0861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 30: Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Bagging with Decision Trees\n",
        "bag_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred_bag = bag_clf.predict(X_test)\n",
        "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
        "\n",
        "# Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Bagging Classifier Accuracy: {acc_bag:.4f}\")\n",
        "print(f\"Random Forest Classifier Accuracy: {acc_rf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOg2__1vKvF4",
        "outputId": "6df65f19-864c-40d7-8f75-0aef61b6ba33"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 1.0000\n",
            "Random Forest Classifier Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 31: Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Accuracy after tuning:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-eI7_QeKyid",
        "outputId": "162dee10-a149-4cc9-a06b-5104aed41b52"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Accuracy after tuning: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 32: Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "for n_estimators in [10, 30, 50, 100]:\n",
        "    bag_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n_estimators, random_state=42)\n",
        "    bag_reg.fit(X_train, y_train)\n",
        "    y_pred = bag_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Bagging Regressor with {n_estimators} estimators MSE: {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy7RDShtLY6b",
        "outputId": "b1f79e15-5632-41c3-d174-a76b354cfcb4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor with 10 estimators MSE: 0.2862\n",
            "Bagging Regressor with 30 estimators MSE: 0.2620\n",
            "Bagging Regressor with 50 estimators MSE: 0.2579\n",
            "Bagging Regressor with 100 estimators MSE: 0.2568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 33: Train a Random Forest Classifier and analyze misclassified samples.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "misclassified_indices = np.where(y_pred != y_test)[0]\n",
        "print(\"Misclassified sample indices:\", misclassified_indices)\n",
        "print(\"True labels:\", y_test[misclassified_indices])\n",
        "print(\"Predicted labels:\", y_pred[misclassified_indices])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4jbiScRLaex",
        "outputId": "8431dcea-2535-4d3b-ff30-a54f131b2406"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassified sample indices: []\n",
            "True labels: []\n",
            "Predicted labels: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 34: Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Single Decision Tree\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "# Bagging Classifier with Decision Trees\n",
        "bag_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred_bag = bag_clf.predict(X_test)\n",
        "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {acc_dt:.4f}\")\n",
        "print(f\"Bagging Classifier Accuracy: {acc_bag:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLb9acItLcn7",
        "outputId": "017d99bb-32d4-4691-c60c-6c8dc379f52f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 1.0000\n",
            "Bagging Classifier Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 35: Train a Random Forest Classifier and visualize the confusion matrix.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.target_names)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Random Forest Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "AQjZgqy9Llh4",
        "outputId": "9d0bc343-ebeb-45c3-cfe7-6883a1fb6e40"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 36: Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy.\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('svm', SVC(probability=True)),\n",
        "    ('lr', LogisticRegression(max_iter=1000))\n",
        "]\n",
        "\n",
        "stack_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "stack_clf.fit(X_train, y_train)\n",
        "y_pred = stack_clf.predict(X_test)\n",
        "\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNHkUHQILnen",
        "outputId": "529f31e3-665d-400c-a96f-885a5ecc9938"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 37: Train a Random Forest Classifier and print the top 5 most important features.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "importances = rf_clf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "print(\"Top 5 important features:\")\n",
        "for i in range(5):\n",
        "    print(f\"{data.feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx7U3MivLpdx",
        "outputId": "418480a0-44b3-4562-d449-b611a2971773"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 important features:\n",
            "mean concave points: 0.1419\n",
            "worst concave points: 0.1271\n",
            "worst area: 0.1182\n",
            "mean concavity: 0.0806\n",
            "worst radius: 0.0780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 38: Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score.\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "bag_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "\n",
        "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buySmFkKLrvq",
        "outputId": "52432fef-90b8-4804-b178-ec33b2bdb52a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 Score (macro): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 39: Train a Random Forest Classifier and analyze the effect of max_depth on accuracy.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "for depth in [None, 2, 4, 6, 8]:\n",
        "    rf = RandomForestClassifier(max_depth=depth, n_estimators=100, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Max Depth = {depth}: Accuracy = {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rsLzySkLvBU",
        "outputId": "a436434e-5e8a-4c18-ecc8-9744f5c18da3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth = None: Accuracy = 1.0000\n",
            "Max Depth = 2: Accuracy = 1.0000\n",
            "Max Depth = 4: Accuracy = 1.0000\n",
            "Max Depth = 6: Accuracy = 1.0000\n",
            "Max Depth = 8: Accuracy = 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 40: Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance.\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "estimators = {\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"KNeighbors\": KNeighborsRegressor()\n",
        "}\n",
        "\n",
        "for name, estimator in estimators.items():\n",
        "    bag_reg = BaggingRegressor(estimator=estimator, n_estimators=50, random_state=42)\n",
        "    bag_reg.fit(X_train, y_train)\n",
        "    y_pred = bag_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Bagging Regressor with {name} MSE: {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOkIxRbYLxDi",
        "outputId": "187fb41c-d031-4951-d4ef-29ce8f493f5f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor with Decision Tree MSE: 0.2579\n",
            "Bagging Regressor with KNeighbors MSE: 1.1021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 41: Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "auc_score = roc_auc_score(y_test, y_proba)\n",
        "print(\"ROC-AUC Score:\", auc_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJL5tNpsLyji",
        "outputId": "5353c94f-2df0-4bc7-a844-f0c45b548c19"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9968400940623163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 42: Train a Bagging Classifier and evaluate its performance using cross-validation.\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "bag_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "scores = cross_val_score(bag_clf, X, y, cv=5, scoring='accuracy')\n",
        "print(\"Cross-validation accuracies:\", scores)\n",
        "print(\"Mean CV accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbyCrC_wL2K3",
        "outputId": "82974bff-9deb-47ac-c68a-d4b9ab8db368"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation accuracies: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
            "Mean CV accuracy: 0.9666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 43: Train a Random Forest Classifier and plot the Precision-Recall curve.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_scores = rf_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "plt.step(recall, precision, where='post')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title(f'Precision-Recall curve: AP={avg_precision:.2f}')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7HxOD-6DL32W",
        "outputId": "cd3b5ebf-2302-4c15-ec1c-9af1707ac460"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 44: Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy.\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=1000))\n",
        "]\n",
        "\n",
        "stack_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "stack_clf.fit(X_train, y_train)\n",
        "y_pred = stack_clf.predict(X_test)\n",
        "\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwfnWEinL5sm",
        "outputId": "708118f3-03ce-4422-adc7-f950fac847c7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 45: Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "for bootstrap in [True, False]:\n",
        "    bag_reg = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(),\n",
        "        n_estimators=50,\n",
        "        bootstrap=bootstrap,\n",
        "        random_state=42\n",
        "    )\n",
        "    bag_reg.fit(X_train, y_train)\n",
        "    y_pred = bag_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Bootstrap={bootstrap} Bagging Regressor MSE: {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlH9xuSYL7ZR",
        "outputId": "f4374125-7123-4cb9-9514-015cff5c3367"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap=True Bagging Regressor MSE: 0.2579\n",
            "Bootstrap=False Bagging Regressor MSE: 0.4967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EFogAYEGL9YW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}